{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNj1mmNDik3L"
      },
      "source": [
        "\n",
        "## Классификация изображений из датасета [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzke8YgukOQt"
      },
      "source": [
        "## Задание:\n",
        "\n",
        "Реализовать алгоримтм позволяющий классифицировать изображения из датасета CIFAR-10 и оценить качество его работы.\n",
        "\n",
        "Требования:\n",
        "\n",
        "1. Можете придумать свой алгоритм, загрузить готовую модель или использовать собственную архитектуру.\n",
        "\n",
        "2. Не используйте предобученные модели.\n",
        "\n",
        "3. Выберите способ оценки качества предсказаний модели. Обоснуйте его.\n",
        "\n",
        "4. Проведите обучение. Продемонстрируйте умение использовать соответствующие инструменты.\n",
        "\n",
        "5. Оцените полученный результат.\n",
        "\n",
        "*Не используйте инструменты принцип работы которых вам непонятен."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torchvision\n",
        "%pip install scikit-learn\n",
        "%pip install numpy\n",
        "%pip install pillow\n",
        "%pip install scikit-image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF_0Fa4Smllm"
      },
      "source": [
        "### Данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models, datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Download a CIFAR10 dataset\n",
        "dataset = datasets.CIFAR10(\"content\", train=True, download=True, transform=ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: airplane\n",
            "1: automobile\n",
            "2: bird\n",
            "3: cat\n",
            "4: deer\n",
            "5: dog\n",
            "6: frog\n",
            "7: horse\n",
            "8: ship\n",
            "9: truck\n"
          ]
        }
      ],
      "source": [
        "class_names = dataset.classes\n",
        "\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"{i}: {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.22723313 0.20370372 0.26111114 ... 0.46013075 0.2697168  0.26830065]\n",
            " [0.5633987  0.50228757 0.45653597 ... 0.5002179  0.5074074  0.5205883 ]\n",
            " [0.99891067 0.99346405 0.99346405 ... 0.31383443 0.31753814 0.32712418]\n",
            " ...\n",
            " [0.20544665 0.19498911 0.1969499  ... 0.30446625 0.2724401  0.21252725]\n",
            " [0.7639434  0.7523965  0.7490196  ... 0.6149238  0.6518519  0.64738566]\n",
            " [0.858061   0.8898693  0.8955338  ... 0.69978213 0.6877996  0.68867105]]\n",
            "[6 9 9 ... 9 1 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "\n",
        "labels = np.array([label for image, label in dataset])\n",
        "data = np.array([np.array(image).flatten() for image, label in dataset])\n",
        "\n",
        "# Сжатие изображения до 24x24 пикселей (для ускорения обучения)\n",
        "data = np.array([resize(image.reshape(32, 32, 3), (24, 24, 3)).flatten() for image in data])\n",
        "\n",
        "print(data)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Разделение на тренировочные и тестовые данные (чтобы избежать переобучения)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=45)\n",
        "\n",
        "# Для SVM используем 50% данных для ускорения обучения (иначе долго будет обрабатываться, т.к. большой объём датасета)\n",
        "subset_size = int(0.5 * len(dataset))\n",
        "subset_indices = np.random.choice(len(dataset), subset_size, replace=False)\n",
        "subset_data = data[subset_indices]\n",
        "subset_labels = labels[subset_indices]\n",
        "\n",
        "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(subset_data, subset_labels, test_size=0.2, random_state=67)\n",
        "\n",
        "# SVM чувствительна к масштабу данных\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_scaled)\n",
        "X_test_scaled = scaler.transform(X_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrwJDAvpmk1W"
      },
      "source": [
        "### Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### С этими моделями выполняла семинарские задачи по мат методам на 3-м курсе"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Tn23bO_7mt14"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale')\n",
        "\n",
        "# радиальное базисное ядро подходит для более сложных границ разделения, по идее для изображений как раз подойдет\n",
        "# scale gamma рекомендуется для больших данных\n",
        "# через увеличение C уменьшаем регуляризацию -- появляется больше границ между классами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOz3OZAomvXO"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QMh6R6o3m8Mr"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=10)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm.fit(X_train_scaled, y_train_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjn4HSSEm28g"
      },
      "source": [
        "### Оценка результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Выбраны метрики качества:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Accuracy, доля правильно классифицированных изображений, простой и наглядный способ оценки\n",
        "\n",
        "2. Precision, Recall, F1-score (через classification_report): эти метрики полезны, т.к. учитывают баланс между ложноположительными и ложноотрицательными предсказаниями; показывают, как модель справляется с отдельными классами\n",
        "\n",
        "3. Precision: как много предсказанных позитивных случаев являются истинно позитивными\n",
        "4. Recall: сколько из всех истинных позитивных случаев было найдено\n",
        "5. F1-score -- гармоническое среднее между precision и recall\n",
        "\n",
        "6. Confusion Matrix: матрица показывает, какие классы модель путает между собой"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OXH43MRWm7Ku"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestClassifier metrics:\n",
            "\n",
            "Accuracy: 0.46\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.57      0.56      1017\n",
            "           1       0.50      0.53      0.51      1026\n",
            "           2       0.37      0.33      0.34       991\n",
            "           3       0.35      0.30      0.32       945\n",
            "           4       0.39      0.36      0.38      1047\n",
            "           5       0.41      0.38      0.39       993\n",
            "           6       0.44      0.53      0.48       986\n",
            "           7       0.52      0.46      0.49      1039\n",
            "           8       0.57      0.60      0.58       960\n",
            "           9       0.49      0.56      0.52       996\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.46      0.46      0.46     10000\n",
            "weighted avg       0.46      0.46      0.46     10000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[581  52  43  23  31  20  27  26 163  51]\n",
            " [ 35 546  20  39  25  25  35  32  69 200]\n",
            " [ 93  46 323  66 136  73 116  74  34  30]\n",
            " [ 34  42  73 284  84 178 110  53  25  62]\n",
            " [ 72  32 146  68 381  48 160  97  19  24]\n",
            " [ 20  38 102 152  69 373 101  76  21  41]\n",
            " [ 25  35  81  77 106  61 525  34   9  33]\n",
            " [ 53  45  63  62 109  66  69 479  19  74]\n",
            " [ 92  98  14  29  12  29  19  13 576  78]\n",
            " [ 47 168  17  15  18  26  28  34  82 561]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "print('RandomForestClassifier metrics:\\n')\n",
        "\n",
        "y_pred_rfc = rfc.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rfc):.2f}\\n\")\n",
        "print(classification_report(y_test, y_pred_rfc))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rfc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM metrics:\n",
            "\n",
            "Accuracy: 0.53\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.61      0.57       503\n",
            "           1       0.63      0.63      0.63       511\n",
            "           2       0.42      0.44      0.43       504\n",
            "           3       0.36      0.38      0.37       502\n",
            "           4       0.45      0.45      0.45       483\n",
            "           5       0.43      0.40      0.41       499\n",
            "           6       0.57      0.58      0.57       499\n",
            "           7       0.63      0.55      0.59       498\n",
            "           8       0.68      0.64      0.66       483\n",
            "           9       0.60      0.58      0.59       518\n",
            "\n",
            "    accuracy                           0.53      5000\n",
            "   macro avg       0.53      0.53      0.53      5000\n",
            "weighted avg       0.53      0.53      0.53      5000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[308  21  30  17  21  12  10  15  41  28]\n",
            " [ 27 324   9  12   8  12  12  13  22  72]\n",
            " [ 43   7 221  39  63  41  50  20  10  10]\n",
            " [ 20  13  49 192  20  98  53  22  15  20]\n",
            " [ 37   6  78  34 217  24  42  34   6   5]\n",
            " [ 15  12  52 113  39 199  30  20   7  12]\n",
            " [  9   7  36  60  41  33 287  10   5  11]\n",
            " [ 26  11  34  33  48  30  12 273   8  23]\n",
            " [ 60  33  11  24   9   7   2   3 309  25]\n",
            " [ 34  82  11  11  11  11   5  21  29 303]]\n"
          ]
        }
      ],
      "source": [
        "print('SVM metrics:\\n')\n",
        "\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test_scaled, y_pred_svm):.2f}\\n\")\n",
        "print(classification_report(y_test_scaled, y_pred_svm))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_scaled, y_pred_svm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O28yk5z1lsIv"
      },
      "source": [
        "## Вывод\n",
        "\n",
        "#### Получен сомнительный результат точности моделей: 0.46 и 0.53, выбранные модели -- далеко не лучший выбор для классификации изображений. Читала, что свёрточные нейронные сети хороши в этой области, но с ними я не работала\n",
        "\n",
        "#### Лучше всего распознаются классы (более высокие показатели метрик precision, recall и f1-score): 0 (самолет), 1 (автомобиль), 6 (лягушка), 7 (лошадь), 8 (корабль) и 9 (грузовик) — наверное, из-за чётких визуальных границ эти объекты более узнаваемы (особенно техника)\n",
        "\n",
        "#### С классами 2 (птица), 3 (кошка), 4 (олень), 5 (собака) возникают сложности распознавания: причинами могут являться разнообразие видов (что усложняет классификацию в плане определения общего) -- для 2, 3 и 5; в случае 4 причиной может быть потеря рогов при сжатии и схожесть с лошадью\n",
        "\n",
        "#### По матрице ошибок можно предположить, что класс автомобиля местами путается с классом грузовика, а класс самолета с классом корабля, что по идее можно объяснить схожим внешним видом конструкций\n",
        "\n",
        "#### Cжатие изображений до меньшего разрешения (24x24 пикселя) скорее всего повлияло на ухудшение качества распознавания, особенно для менее чётких объектов (2, 3, 5), как и урезание выборки для SVM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exWY19FHlw3C"
      },
      "source": [
        "Будьте готовы ответить на любые вопросы по коду, процессу обучения, моделям и метрикам."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
